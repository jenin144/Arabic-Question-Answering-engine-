import re
import pandas as pd
from rank_bm25 import BM25Okapi
from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification
from src.preprocess import load_data, preprocess_documents, create_inverted_index
from src.search import preprocess_query
from src.answer_extraction import load_ner_model, calculate_ner_tfidf_score, extract_answers_with_ner_arabic, extract_best_answer_traditional_inverted_index

# Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©
bm25_model = None
ner_pipeline = None
df = None
qa_pipeline = None
inverted_index = None

# Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø© Ù„Ù„Ù€ Hybrid Score
ALPHA = 0.6  # ÙˆØ²Ù† BM25
BETA = 0.4   # ÙˆØ²Ù† NER+TFIDF

# Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
def initialize_system():
    global bm25_model, df, qa_pipeline, inverted_index, ner_pipeline
    if df is not None:
        return
    
    print("ðŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    df = load_data("data/QAfull.csv")
    
    print("ðŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚...")
    df = preprocess_documents(df)
    inverted_index = create_inverted_index(df)
    
    print("ðŸ”„ Ø¥Ø¹Ø¯Ø§Ø¯ BM25...")
    tokenized = df['Tokenized_Document'].tolist()
    bm25_model = BM25Okapi(tokenized)
    
    # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ QA
    try:
        qa_pipeline = pipeline(
            "question-answering",
            model="deepset/xlm-roberta-large-squad2",
            tokenizer="deepset/xlm-roberta-large-squad2"
        )
        print("âœ… Ù†Ù…ÙˆØ°Ø¬ QA Ø¬Ø§Ù‡Ø²")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ QA: {e}")
        qa_pipeline = None
    
    # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ NER
    try:
        ner_pipeline = load_ner_model()
        print("âœ… Ù†Ù…ÙˆØ°Ø¬ NER Ø¬Ø§Ù‡Ø²")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ NER: {e}")
        ner_pipeline = None


def extract_with_qa_model(doc_text, query, debug=False):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ QA"""
    if not qa_pipeline:
        return None, 0.0
    
    try:
        # ØªÙ‚Ù„ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
        max_length = 512
        if len(doc_text) > max_length:
            doc_text = doc_text[:max_length]
            
        res = qa_pipeline({"context": doc_text, "question": query})
        return res.get('answer'), res.get('score', 0.0)
    except Exception as e:
        if debug:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù†Ù…ÙˆØ°Ø¬ QA: {e}")
        return None, 0.0


def calculate_hybrid_scores(query_tokens, debug=False):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Hybrid Score Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª"""
    # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø§Øª BM25 Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
    bm25_scores = bm25_model.get_scores(query_tokens)
    
    # ØªØ·Ø¨ÙŠØ¹ Ø¯Ø±Ø¬Ø§Øª BM25 (0-1)
    max_bm25 = max(bm25_scores) if max(bm25_scores) > 0 else 1
    normalized_bm25 = [score / max_bm25 for score in bm25_scores]
    
    hybrid_scores = []
    
    for idx, bm25_score in enumerate(normalized_bm25):
        doc_text = df.iloc[idx]['doc']
        
        # Ø­Ø³Ø§Ø¨ NER+TFIDF score
        if ner_pipeline:
            ner_tfidf_score = calculate_ner_tfidf_score(doc_text, query_tokens, ner_pipeline)
        else:
            ner_tfidf_score = 0.0
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Hybrid Score
        hybrid_score = ALPHA * bm25_score + BETA * ner_tfidf_score
        
        hybrid_scores.append({
            'index': idx,
            'hybrid_score': hybrid_score,
            'bm25_score': bm25_score,
            'ner_tfidf_score': ner_tfidf_score
        })
        
        if debug and idx < 5:  # Ø·Ø¨Ø§Ø¹Ø© Ø£ÙˆÙ„ 5 Ù„Ù„ØªØµØ­ÙŠØ­
            print(f"Doc {idx}: BM25={bm25_score:.3f}, NER+TFIDF={ner_tfidf_score:.3f}, Hybrid={hybrid_score:.3f}")
    
    # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù€ Hybrid Score
    hybrid_scores.sort(key=lambda x: x['hybrid_score'], reverse=True)
    
    return hybrid_scores


def process_query_enhanced(query, debug=False):
    """Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Hybrid Ranking"""
    initialize_system()
    
    if debug:
        print(f"\nðŸ” Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {query}")
        print(f"âš–ï¸ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©: Î±={ALPHA}, Î²={BETA}")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
    tokens = preprocess_query(query)
    if not tokens:
        return {'query': query, 'top_answers': [], 'error': 'Ù„Ø§ Ø£ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„'}
    
    if debug:
        print(f"ðŸ”¤ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {tokens}")
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Hybrid Scores ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
    ranked_docs = calculate_hybrid_scores(tokens, debug)
    
    answers = []
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ 5 Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù€ Hybrid Score
    for rank, doc_info in enumerate(ranked_docs[:5], start=1):
        idx = doc_info['index']
        doc = df.iloc[idx]
        doc_id, doc_text, url = doc['QID'], doc['doc'], doc.get('url', '')
        
        # ØªÙˆØ²ÙŠØ¹ Ø·Ø±Ù‚ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨
        if rank == 1:
            # Ø§Ù„Ù…Ø±ØªØ¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: QA Model
            ans, conf = extract_with_qa_model(doc_text, query, debug)
            method = 'qa_model'
            if debug:
                print(f"ðŸ¥‡ Ø§Ù„Ù…Ø±ØªØ¨Ø© {rank}: QA Model - Ø§Ù„Ø«Ù‚Ø©: {conf:.3f}")
                
        elif rank == 2:
            # Ø§Ù„Ù…Ø±ØªØ¨Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: NER+TFIDF
            ans = extract_answers_with_ner_arabic(doc_text, tokens, ner_pipeline)
            method = 'ner_tfidf'

            if debug:
                print(f"ðŸ¥ˆ Ø§Ù„Ù…Ø±ØªØ¨Ø© {rank}: NER+TFIDF")
                
        else:
            # Ø§Ù„Ù…Ø±Ø§ØªØ¨ Ø§Ù„Ø£Ø®Ø±Ù‰: Traditional
            ans = extract_best_answer_traditional_inverted_index(doc_id, tokens, inverted_index, df)
            conf = 0.0
            method = 'traditional'
            if debug:
                print(f"ðŸ¥‰ Ø§Ù„Ù…Ø±ØªØ¨Ø© {rank}: Traditional")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        if ans and len(ans.strip()) >= 20:
            answers.append({
                'rank': rank,
                'answer': ans.strip(),
                'document_id': doc_id,
                'hybrid_score': doc_info['hybrid_score'],
                'bm25_score': doc_info['bm25_score'],
                'ner_tfidf_score': doc_info['ner_tfidf_score'],
                'qa_confidence': conf,
                'extraction_method': method,
                'source_link': url
            })
            
            if debug:
                print(f"   âœ… Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù‚Ø¨ÙˆÙ„Ø©: {ans[:100]}...")
        else:
            if debug:
                print(f"   âŒ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø±ÙÙˆØ¶Ø© (Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹)")
        
        # Ø¥ÙŠÙ‚Ø§Ù Ø¹Ù†Ø¯ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ 3 Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¬ÙŠØ¯Ø©
        if len(answers) >= 3:
            break
    
    result = {
        'query': query,
        'top_answers': answers,
        'total_documents': len(df),
        'hybrid_params': {'alpha': ALPHA, 'beta': BETA},
        'error': None if answers else 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø©'
    }
    
    if debug:
        print(f"\nðŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {len(answers)} Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø£ØµÙ„ {len(ranked_docs)} Ù…Ø³ØªÙ†Ø¯")
    
    return result


def main_process_query(query, debug=False):
    """Ø¯Ø§Ù„Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
    return process_query_enhanced(query, debug=debug)


def set_hybrid_weights(alpha, beta):
    """ØªØ¹Ø¯ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©"""
    global ALPHA, BETA
    if alpha + beta != 1.0:
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        total = alpha + beta
        alpha = alpha / total
        beta = beta / total
    
    ALPHA = alpha
    BETA = beta
    print(f"âš–ï¸ ØªÙ… ØªØ­Ø¯ÙŠØ« Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©: Î±={ALPHA:.2f}, Î²={BETA:.2f}")


def main_process_query(query, debug=False):
    return process_query_enhanced(query, debug=debug)


# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
if __name__ == '__main__':
    print("ðŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø¯Ø±Ø¬Ø© ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    result = process_query_enhanced("Ù…Ø§ Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø³ÙƒØ±ÙŠØŸ", debug=True)
    
    print(f"\nðŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print(f"Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {result['query']}")
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª: {len(result['top_answers'])}")
    
    for a in result['top_answers']:
        print(f"\nðŸ”¹ Ø¥Ø¬Ø§Ø¨Ø© {a['rank']}:")
        print(f"   Ø§Ù„Ù†Øµ: {a['answer'][:150]}...")
        print(f"   Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: {a['extraction_method']}")
        print(f"   Ø§Ù„Ø¯Ø±Ø¬Ø§Øª: Hybrid={a['hybrid_score']:.3f}, BM25={a['bm25_score']:.3f}, NER+TFIDF={a['ner_tfidf_score']:.3f}")
        if a['qa_confidence'] > 0:
            print(f"   Ø«Ù‚Ø© QA: {a['qa_confidence']:.3f}")